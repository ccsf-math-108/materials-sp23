{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw05.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"display: block; margin-left: auto; margin-right: auto\" src=\"./ccsf-logo.png\" width=\"250rem;\" alt=\"The CCSF black and white logo\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h1>Homework 5: Applying Functions and Iteration</h1>\n",
    "    <em>View the related <a href=\"https://ccsf.instructure.com\" target=\"_blank\">Canvas</a> Assignment page for additional details.</em>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please complete this notebook by filling in the cells provided. \n",
    "\n",
    "**Throughout this homework and all future ones, please be sure to not re-assign variables throughout the notebook! For example, if you use `max_temperature` in your answer to one question, do not reassign it later on. Moreover, please be sure to only put your written answers in the provided cells.**\n",
    "\n",
    "Run the following cell to import the modules and settings needed for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datascience import *\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022-23 CCSF Football Season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are going to analyze how well the CCSF football team performed in the 2022-23 season. A football game is divided into four periods, called quarters. The number of points CCSF scored in each quarter, and the number of points their opponent scored in each quarter are stored in a table called `ccsf_fb.csv`.\n",
    "\n",
    "Note that the 2022-23 season data was collected from [the CCSF Athletics website](https://ccsfathletics.com/sports/fball/2022-23/teams/sanfrancisco)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "games = Table().read_table(\"ccsf_fb.csv\")\n",
    "games.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by finding the total points each team scored in a game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 01 📍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function called `sum_scores`.  It should take five arguments, where each argument is the team's quarter or overt time score. It should return the team's total score for that game.\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sum_scores(...):\n",
    "     \"\"\"Returns the total score calculated by adding up the score of each quarter and the over time\"\"\"\n",
    "     ...\n",
    "\n",
    "sum_scores(14, 7, 3, 0, 3) #DO NOT CHANGE THIS LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 02 📍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new table `final_scores` with three columns in this *specific* order: `Opponent`, `CCSF Score`, `Opponent Score`. You will have to create the `CCSF Score` and `Opponent Score` columns. Use the function `sum_scores` you just defined in the previous question for this problem.\n",
    "\n",
    "*Hint:* If you want to apply a function that takes in multiple arguments, you can pass multiple column names as arguments in `tbl.apply()`. The column values will be passed into the corresponding arguments of the function. Take a look at the python reference for syntax.\n",
    "\n",
    "*Tip:* If you’re running into issues creating final_scores, check that `ccsf_scores` and `opponent_scores` output what you want. \n",
    "\n",
    "\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ccsf_scores = ...\n",
    "opponent_scores = ...\n",
    "final_scores = ...\n",
    "final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get specific row objects from a table. You can use `tbl.row(n)` to get the `n`th row of a table. `row.item(\"column_name\")` will allow you to select the element that corresponds to `column_name` in a particular row. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Just run this cell\n",
    "games.row(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Just run this cell\n",
    "games.row(10).item(\"CCSF 4Q\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 03 📍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to see for a particular game whether or not CCSF won. Write a function called `did_ccsf_win`.  It should take one argument: a row object from the `final_scores` table. It should return either `True` if CCSF's score was greater than the Opponent's score, and `False` otherwise.\n",
    "\n",
    "\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ...(row):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_03\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 04 📍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, CCSF did not win against every opponent during the 2022-23 season. Using the `final_scores` table, assign `results` to an array of `True` and `False` values that correspond to whether or not CCSF won. Add the `results` array to the `final_scores` table, and assign this to `final_scores_with_results`. Then, respectively assign the number of wins and losses CCSF had to `ccsf_wins` and `ccsf_losses`.\n",
    "\n",
    "*Hint*: When you only pass a function name and no column labels through `tbl.apply()`, the function gets applied to every row in `tbl`\n",
    "\n",
    "\n",
    "\n",
    "_Points:_ 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = ...\n",
    "final_scores_with_results = ...\n",
    "ccsf_wins = ...\n",
    "ccsf_losses = ...\n",
    "\n",
    "# Don't delete or edit the following line:\n",
    "print(f\"In the 2022-23 Season, CCSF Football won {ccsf_wins} games and lost {ccsf_losses} games. Go RAMS!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_04\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 05 📍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes in football the two teams are equally matched and the game is quite close. Other times, it is a blowout, where the winning team wins by a large margin of victory. Let's define a **big win** to be a game in which the winning team won by more than 10 points. Use your `final_scores` table to assign `big_wins` to an array of team names that CCSF had big wins against during the 2022-23 football season. You may find the `is_big_win` function defined below helpful to you.\n",
    "\n",
    "\n",
    "_Points:_ 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_big_win(row):\n",
    "    '''Return a boolean to describe whether or not a game (row) is a big win'''\n",
    "    score_diff = row.item(\"CCSF Score\") - row.item(\"Opponent Score\")\n",
    "    \n",
    "    if score_diff > 10:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "big_wins = ...\n",
    "\n",
    "for row in ...: # Iterate through rows of final_scores table\n",
    "    opponent =  ...\n",
    "    if ...: # You should use the above function\n",
    "        big_wins = np.append(big_wins, ...)\n",
    "\n",
    "big_wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unrolling `for` Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 06 📍🔎"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "\"Unrolling\" a `for` loop means to manually write out all the code that it executes.  The result is code that does the same thing as the loop, but without the structure of the loop.  For example, for the following loop:\n",
    "\n",
    "    for num in np.arange(3):\n",
    "        print(\"The number is\", num)\n",
    "        \n",
    "The unrolled version would look like this:\n",
    "\n",
    "    print(\"The number is\", 0)\n",
    "    print(\"The number is\", 1)\n",
    "    print(\"The number is\", 2)\n",
    "\n",
    "Unrolling a `for` loop is a great way to understand what the loop is doing during each step. In this exercise, you'll practice unrolling a `for` loop.\n",
    "\n",
    "In the question below, write code that does the same thing as the following, but with the `for` loop unrolled. Be careful of the spacing on this code segment!\n",
    "\n",
    "```python\n",
    "for joke_iteration in np.arange(3):\n",
    "    print(\"Knock, knock.\")\n",
    "    print(\"Who's there?\")\n",
    "    print(\"Banana.\")\n",
    "    print(\"Banana who?\")\n",
    "print(\"Knock, knock.\")\n",
    "print(\"Who's there?\")\n",
    "print(\"Orange.\")\n",
    "print(\"Orange who?\")\n",
    "print(\"Orange you glad I didn't say banana?\")\n",
    "```\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Submit your Homework to Canvas\n",
    "\n",
    "Once you have finished working on the homework tasks, prepare to submit your work in Canvas by completing the following steps.\n",
    "\n",
    "1. In the related Canvas Assignment page, check the rubric to know how you will be scored for this assignment.\n",
    "2. Double-check that you have run the code cell near the end of the notebook that contains the command `\"grader.check_all()\"`. This command will run all of the run tests on all your responses to the auto-graded tasks marked with 📍.\n",
    "3. Double-check your responses to the manually graded tasks marked with 📍🔎.\n",
    "3. Select the menu item \"File\" and \"Save Notebook\" in the notebook's Toolbar to save your work and create a specific checkpoint in the notebook's work history.\n",
    "4. Select the menu items \"File\", \"Download\" in the notebook's Toolbar to download the notebook (.ipynb) file. \n",
    "5. In the related Canvas Assignment page, click Start Assignment or New Attempt to upload the downloaded .ipynb file.\n",
    "\n",
    "**Keep in mind that the autograder does not always check for correctness. Sometimes it just checks for the format of your answer, so passing the autograder for a question does not mean you got the answer correct for that question.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "otter": {
   "OK_FORMAT": true,
   "assignment_name": "hw05_sp23",
   "tests": {
    "task_01": {
     "name": "task_01",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> \n>>> sum_scores(14, 7, 3, 0, 3) == 27 and sum_scores(2, 3, 6, 1, 0) == 12\nTrue",
         "failure_message": "❌ Your function doesn't seem to work correctly with our 4 quarter scores and over time score.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "✅ Your function works with our 4 quarter scores and over time score."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_02": {
     "name": "task_02",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> \n>>> final_scores.num_columns == 3\nTrue",
         "failure_message": "❌ final_scores does not have the correct number of columns.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "✅ final_scores has the correct number of columns."
        },
        {
         "code": ">>> \n>>> set(['Opponent', 'CCSF Score', 'Opponent Score']) == set(final_scores.labels)\nTrue",
         "failure_message": "❌ final_scores does not have the correct labels.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "✅ final_scores has the correct labels."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_03": {
     "name": "task_03",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> \n>>> 'did_ccsf_win' in globals() and callable(did_ccsf_win)\nTrue",
         "failure_message": "❌ You didn't create a function called did_ccsf_win.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "✅ You've created a function called did_ccsf_win."
        },
        {
         "code": ">>> \n>>> did_ccsf_win(final_scores.row(1)) == False\nTrue",
         "failure_message": "❌ Your function doesn't that CCSF won against Sacramento City.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "✅ Your function shows that CCSF won against Sacramento City."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_04": {
     "name": "task_04",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> \n>>> 0 <= ccsf_wins <= 11\nTrue",
         "failure_message": "❌ There were only 13 games, so CCSF won 0, 1, 2, ..., or 11 games.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "✅ ccsf_wins is a possible value"
        },
        {
         "code": ">>> \n>>> 0 <= ccsf_losses <= 11\nTrue",
         "failure_message": "❌ There were only 13 games, so CCSF lost 0, 1, 2, ..., or 11 games.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "✅ ccsf_losses is a possible value"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_05": {
     "name": "task_05",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> \n>>> row.item('CCSF Score') == 34\nTrue",
         "failure_message": "❌ One of the row items we checked doesn't the correct CCSF Score.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "✅ One of the row items we checked has the correct CCSF Score."
        },
        {
         "code": ">>> \n>>> 0 <= len(big_wins) <= 11\nTrue",
         "failure_message": "❌ There is not a possible value for the number items in big_wins.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "✅ There is a possible value for the number items in big_wins."
        },
        {
         "code": ">>> \n>>> type(big_wins.item(0)) == str\nTrue",
         "failure_message": "❌ The first item in big_wins is not a string.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "✅ The first item in big_wins is a string."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
