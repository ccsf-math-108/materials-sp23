{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab08.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"display: block; margin-left: auto; margin-right: auto\" src=\"./ccsf-logo.png\" width=\"250rem;\" alt=\"The CCSF black and white logo\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h1>Lab 08: A/B Testing</h1>\n",
    "    <em>View the related <a href=\"https://ccsf.instructure.com\" target=\"_blank\">Canvas</a> Assignment page for additional details.</em>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This week's lab will focus on A/B Testing using data from the ever-popular British television show, [*The Great British Bakeoff*](https://en.wikipedia.org/wiki/The_Great_British_Bake_Off)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datascience import *\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "from matplotlib import patches\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Great British Bake Off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">\"The Great British Bake Off (often abbreviated to Bake Off or GBBO) is a British television baking competition, produced by Love Productions, in which a group of amateur bakers compete against each other in a series of rounds, attempting to impress a group of judges with their baking skills\" [Source: Wikipedia](https://en.wikipedia.org/wiki/The_Great_British_Bake_Off)\n",
    "\n",
    "For every week of the competition, the judges assign one contestant the title \"Star Baker\". Ultimately, one winner is crowned every season. Using this information, we would like to investigate how winning Star Baker awards affects the odds of winning a season of the show."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 01 üìçüîé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "We want to know whether winning more Star Baker awards causes a change in likelihood of winning the season. Why is it not sufficient to compare star baker rates for winners and losers?\n",
    "\n",
    "_Check your response with someone else before moving on._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "We are going to run the following hypothesis test to determine the association between winning and number of Star Baker awards. The population we are examining is every contestant from seasons 2 through 11 of GBBO. We are going to use the following null and alternative hypotheses:\n",
    "\n",
    "**Null hypothesis:** The distribution of Star Baker awards between contestants who won their season and contestants who did not win their season is the same.\n",
    "\n",
    "**Alternative hypothesis:** Contestants who win their season of the show will win more Star Baker awards on average.\n",
    "\n",
    "Our alternative hypothesis is related to our suspicion that contestants who win more Star Baker awards are more skilled, so they are more likely to win the season."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `bakers` table below describes the number of star baker awards each contest won and whether or not they won their season (`1` if they won, `0` if they did not win). The data was manually aggregated from Wikipedia for seasons 2-11 of the show. We randomized the order of rows as to not spoil the outcome of the show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bakers = Table.read_table(\"star_bakers.csv\")\n",
    "bakers.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 02 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'star baker awards mean', 'won'Create a new table called `means` that contains the mean number of star baker awards for bakers who did not win (`won==0`) and bakers that did win (`won==1`). The table should have the column names `won` and `star baker awards mean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "means = ...\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 03 üìçüîé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Visualize the distribution of Star Baker awards for winners and non-winners as overlaid histograms. Make sure to:\n",
    "\n",
    "* Use the bins we provided.\n",
    "* Use the group argument of `tbl.hist`. In order to produce several overlayed histograms based on unique values in a given column, we can do something like `tbl.hist(..., group=<col_name>, bins=...)`!\n",
    "\n",
    "_We recommend that you check your histogram with someone before moving on._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "useful_bins = np.arange(0, 7)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Task 04 üìçüîé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "We want to figure out if there is a difference between the distribution of Star Baker awards between winners and non winners. For the test statistic, subtract the mean star baker awards value for those that didn't win from the mean value for those that did win.\n",
    "\n",
    "Which values of this test statistic support the alternative hypothesis?\n",
    "\n",
    "_Before moving on, confirm your answer with someone._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Task 05 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `observed_difference` to the observed test statistic using the `means` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "observed_difference = ...\n",
    "observed_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 06 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shortly, you will be calculating that difference on a variety of tables similar to `bakers`, but with the mean values shuffled around. Given a table like `bakers`, a label column `label_col` with two labels, `1` and `0`, and a values column `val_col`, write a function `find_test_stat` that calculates the test statistic outlined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_test_stat(tbl, label_col, val_col):\n",
    "    ...\n",
    "\n",
    "# Confirm that your function produces the same observed difference\n",
    "find_test_stat(bakers, \"won\", \"star baker awards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_06\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run a simulation for A/B testing, we resample by **shuffling the labels** of the original sample. If the null hypothesis is true and the star baker award distributions are the same, we expect that the difference in mean star baker awards to not change when `\"won\"` labels are changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 07 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `simulate_and_test_statistic` to compute one trial of our A/B test. Your function should run a simulation and return a test statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "solution",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simulate_and_test_statistic(tbl, labels_col, values_col):\n",
    "    ...\n",
    "\n",
    "simulate_and_test_statistic(bakers, \"won\", \"star baker awards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_07\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 08 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate 5000 trials of our A/B test and store the test statistics in an array called `differences`. This test will take a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repetitions = ...\n",
    "differences = ...\n",
    "\n",
    "...                                              \n",
    "\n",
    "differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_08\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to view a histogram of your simulated test statistics plotted with your observed test statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table().with_column('Difference Between Group Means', differences).hist(bins=20)\n",
    "plt.scatter(observed_difference, 0, color='red', s=30, zorder=2)\n",
    "plt.ylim(-0.1, 1.35);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 09 üìç"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the p-value for your test and assign it to `empirical_p`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "empirical_p = ...                                             \n",
    "\n",
    "empirical_p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"task_09\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 10 üìçüîé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "1. Using a 5% p-value cutoff, draw a conclusion about the null and alternative hypotheses using more the technical language of hypothesis testing.\n",
    "2. Using simple, non-technical language, what does your analysis tell you about the association between star baker awards and winning? \n",
    "3. What can you claim about causation from your statistical analysis? \n",
    "    \n",
    "Confirm your answer with a peer, instructor, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Submit your Lab to Canvas\n",
    "\n",
    "Once you have finished working on the lab questions, prepare to submit your work in Canvas by completing the following steps.\n",
    "\n",
    "1. In the related Canvas Assignment page, check the requirements for a Complete score for this lab assignments.\n",
    "2. Double-check that you have run the code cell near the end of the notebook that contains the command `\"grader.check_all()\"`. This command will run all of the run tests on all your responses to the auto-graded tasks marked with üìç.\n",
    "3. Double-check your responses to the manually graded tasks marked with üìçüîé.\n",
    "4. Select the menu items \"File\", \"Save and Export Notebook As...\", and \"HTML (.html)\" in the notebook's Toolbar to download an HTML version of this notebook file.\n",
    "5. In the related Canvas Assignment page, click Start Assignment or New Attempt to upload the downloaded HTML file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "otter": {
   "OK_FORMAT": true,
   "assignment_name": "lab08_sp23",
   "tests": {
    "task_02": {
     "name": "task_02",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> \n>>> means.num_rows == 2\nTrue",
         "failure_message": "‚ùå Your table should have 2 rows.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ Your table has 2 rows."
        },
        {
         "code": ">>> \n>>> {'won', 'star baker awards mean', } == set(means.labels)\nTrue",
         "failure_message": "‚ùå Your labels should be 'won' and 'star baker awards mean'.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ Your labels seem correct."
        },
        {
         "code": ">>> \n>>> (np.round(min(means.column(\"star baker awards mean\")), 2) == 0.65\n...  and np.round(max(means.column(\"star baker awards mean\")), 2) == 1.5)\nTrue",
         "failure_message": "‚ùå Your mean values don't seem correct.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ Your mean values seem correct."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_05": {
     "name": "task_05",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> \n>>> isinstance(observed_difference, float)\nTrue",
         "failure_message": "‚ùå Your observed_difference value should be a float.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ Your observed_difference value is a float."
        },
        {
         "code": ">>> \n>>> float(round(observed_difference, 3)) == 0.848\nTrue",
         "failure_message": "‚ùå Your observed_difference value does't seem correct. Double check that you are subtracing the means for the winners and losers. Also, double check the order of your subtraction.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ Your observed_difference value seems correct."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_06": {
     "name": "task_06",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> \n>>> np.isclose(round(find_test_stat(bakers, \"won\", \"star baker awards\"), 3) - 0.848, 0)\nTrue",
         "failure_message": "‚ùå Your function should produce the same observed value as in the previous task.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ It seems like your function correctly produces the same observed value as in the previous task."
        },
        {
         "code": ">>> shifted_indices = np.roll(np.arange(bakers.num_rows), 2)\n>>> shifted_won_vals = bakers.take(shifted_indices).column('won')\n>>> test_tbl = bakers.select('star baker awards').with_column('Shuffled Label', shifted_won_vals)\n>>> np.isclose(round(find_test_stat(test_tbl, \"Shuffled Label\", \"star baker awards\"), 3) - (-0.132), 0)\nTrue",
         "failure_message": "‚ùå Your function should use the arguments tbl, label_col, val_col to do the calculation.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ It seems like your function is using the arguments tbl, label_col, val_col to do the calculation."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_07": {
     "name": "task_07",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> \n>>> test_stat = round(simulate_and_test_statistic(bakers, \"won\", \"star baker awards\"), 3)\n>>> -2 < test_stat < 2\nTrue",
         "failure_message": "‚ùå Your test_stat value should be between -2 and 2. Make sure you are using find_test_stat.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ Your test_stat value is between -2 and 2."
        },
        {
         "code": ">>> \n>>> np.random.seed(1)\n>>> test_stat2 = simulate_and_test_statistic(bakers, \"won\", \"star baker awards\")\n>>> np.round(test_stat2, 3) == -0.023 or np.round(test_stat2, 3) == -0.132\nTrue",
         "failure_message": "‚ùå simulate_and_test_statistic doesn't seem to work as intended. Make sure you are using the sample method with the arguement with_replacement=False to suffle the labels. ",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ simulate_and_test_statistic seems to work for the table we checked."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_08": {
     "name": "task_08",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> \n>>> len(differences)\n5000",
         "failure_message": "‚ùå differences should have 5000 items.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ differences has 5000 items."
        },
        {
         "code": ">>> \n>>> abs(np.average(differences)) < 0.05\nTrue",
         "failure_message": "‚ùå On average, your test statistic should be close to 0.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ On average, your test statistic should is close to 0"
        },
        {
         "code": ">>> \n>>> all(differences == differences.item(0)) == False\nTrue",
         "failure_message": "‚ùå Make sure all of the test statistics are different",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ All of the test statistics are different"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "task_09": {
     "name": "task_09",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> \n>>> 0 <= empirical_p < 0.05\nTrue",
         "failure_message": "‚ùå Your p-value should be less than 5%. (It is rare, but there is a small chance you did everything correctly and you just ended up with a p-value that is 5% or larger. Re-run the code in Task 08 and Task 09 to double check.)",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "‚úÖ Your p-value should be less than 5%."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
